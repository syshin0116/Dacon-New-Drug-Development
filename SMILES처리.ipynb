{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0231bc4e-cf53-4f89-8c67-a9532073b5b9",
   "metadata": {},
   "source": [
    "# SMILES 처리 방법\n",
    "\n",
    "### 1. 분자 지문 (Molecular Fingerprints)\n",
    "1. 데이터 처리: SMILES로부터 분자 지문을 추출\n",
    "2. 모델 학습: 예를 들어 RandomForestRegressor 사용\n",
    "3. 하이퍼파라미터 최적화: GridSearchCV 또는 RandomizedSearchCV 사용\n",
    "\n",
    "- 장점: 빠르고, 이해하기 쉽고, 다양한 머신러닝 알고리즘에 적용하기 쉽다\n",
    "- 단점: 정보의 손실이 있을 수 있고, 분자 구조의 모든 세부 정보를 담기 어렵다\n",
    "\n",
    "### 2. Mol2Vec\n",
    "1. 데이터 처리: SMILES의 각 부분에 대한 임베딩을 생성\n",
    "2. 모델 학습: 예를 들어, RandomForestRegressor 사용\n",
    "3. 하이퍼파라미터 최적화\n",
    "\n",
    "- 장점: 더 복잡한 패턴을 포착할 수 있다\n",
    "- 단점: 학습 시간이 오래 걸릴 수 있고, 해석하기 어려울 수 있다\n",
    "\n",
    "### 3. 그래프 기반 접근법\n",
    "1. 데이터 처리: 분자를 그래프로 변환\n",
    "2. 모델 학습: Graph Neural Networks (GNNs) 사용\n",
    "3. 하이퍼파라미터 최적화\n",
    "\n",
    "- 장점: 분자 구조의 복잡성을 더 잘 모델링할 수 있다\n",
    "- 단점: 계산 비용이 높고, 구현이 복잡할 수 있다\n",
    "\n",
    "### 4. One-hot Encoding\n",
    "1. 데이터 처리: SMILES 문자열의 각 문자를 one-hot 벡터로 인코딩\n",
    "2. 모델 학습: RandomForestRegressor 사용\n",
    "3. 하이퍼파라미터 최적화\n",
    "\n",
    "- 장점: 간단하고 빠르다\n",
    "- 단점: SMILES 문자열의 길이가 다르면 패딩이 필요하고, 문자열의 길이가 길 경우 차원이 높아진다\n",
    "\n",
    "### 5. Sequence Models (RNN, LSTM, GRU 등)\n",
    "1. 데이터 처리: SMILES 문자열을 시퀀스로 변환\n",
    "2. 모델 학습: LSTM 또는 GRU 사용\n",
    "3. 하이퍼파라미터 최적화\n",
    "\n",
    "- 장점: 시퀀스 데이터의 내재된 의미를 잘 포착할 수 있다\n",
    "- 단점: 학습 시간이 오래 걸리고, 복잡한 모델 구조를 필요로 한다\n",
    "\n",
    "### 6. Transformer-based models\n",
    "1. 데이터 처리: SMILES 문자열을 시퀀스로 변환\n",
    "2. 모델 학습: Transformer architecture (e.g., BERT for chemistry) 사용\n",
    "3. 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a0ea6a-ade4-4237-a73f-31a45d361e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Flatten\n",
    "\n",
    "# 데이터 로드\n",
    "train_data = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00e1e7-9119-43e5-80ef-f583d35cf56b",
   "metadata": {},
   "source": [
    "## 1. 분자 지문 (Molecular Fingerprints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950d43b0-9684-4262-8f09-cb7a360adfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for HLM using Fingerprints: 66.60611383280072\n",
      "RMSE for MLM using Fingerprints: 64.16422717594158\n"
     ]
    }
   ],
   "source": [
    "def generate_fingerprint(smiles_string):\n",
    "    mol = Chem.MolFromSmiles(smiles_string)\n",
    "    fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    return list(fingerprint)\n",
    "\n",
    "# Fingerprints 생성\n",
    "train_data['fingerprint'] = train_data['SMILES'].apply(generate_fingerprint)\n",
    "X = list(train_data['fingerprint'])\n",
    "y_HLM = train_data['HLM']\n",
    "y_MLM = train_data['MLM']\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "X_train, X_test, y_train_HLM, y_test_HLM = train_test_split(X, y_HLM, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_MLM, y_test_MLM = train_test_split(X, y_MLM, test_size=0.2, random_state=42)\n",
    "\n",
    "model_HLM = LinearRegression().fit(X_train, y_train_HLM)\n",
    "model_MLM = LinearRegression().fit(X_train, y_train_MLM)\n",
    "\n",
    "y_pred_HLM = model_HLM.predict(X_test)\n",
    "y_pred_MLM = model_MLM.predict(X_test)\n",
    "\n",
    "mse_HLM = mean_squared_error(y_test_HLM, y_pred_HLM)\n",
    "mse_MLM = mean_squared_error(y_test_MLM, y_pred_MLM)\n",
    "rmse_HLM = np.sqrt(mse_HLM)\n",
    "rmse_MLM = np.sqrt(mse_MLM)\n",
    "print(\"RMSE for HLM using Fingerprints:\", rmse_HLM)\n",
    "print(\"RMSE for MLM using Fingerprints:\", rmse_MLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2234ce9-c0ae-4280-aea6-0cab601cff61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "RMSE for MLM: 32.793645901928336\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "RMSE for HLM: 32.16512458417776\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "train_data = pd.read_csv('./submissions/train_linear.csv')\n",
    "test_data = pd.read_csv('./submissions/test_linear.csv')\n",
    "\n",
    "# SMILES 문자열에서 fingerprint를 생성하는 함수\n",
    "def generate_fingerprint(smiles_string):\n",
    "    mol = Chem.MolFromSmiles(smiles_string)\n",
    "    if mol is not None:\n",
    "        fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "        return np.array(fingerprint)\n",
    "    else:\n",
    "        return np.zeros(2048)\n",
    "\n",
    "# Train 데이터에 대해 fingerprints 생성\n",
    "fingerprint_data = np.array(train_data['SMILES'].apply(generate_fingerprint).tolist())\n",
    "fingerprint_df = pd.DataFrame(fingerprint_data, columns=[f'bit_{i}' for i in range(2048)])\n",
    "train_data_expanded = pd.concat([train_data, fingerprint_df], axis=1)\n",
    "\n",
    "# Test 데이터에 대해 fingerprints 생성 (필요한 경우)\n",
    "fingerprint_data_test = np.array(test_data['SMILES'].apply(generate_fingerprint).tolist())\n",
    "fingerprint_df_test = pd.DataFrame(fingerprint_data_test, columns=[f'bit_{i}' for i in range(2048)])\n",
    "test_data_expanded = pd.concat([test_data, fingerprint_df_test], axis=1)\n",
    "\n",
    "def train_and_evaluate(target_column):\n",
    "    # 훈련 데이터 준비\n",
    "    X = train_data_expanded.drop(columns=['id', 'SMILES', 'MLM', 'HLM'])\n",
    "    y = train_data_expanded[target_column]\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 학습\n",
    "    model = RandomForestRegressor()\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # RMSE 계산\n",
    "    predictions = best_model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "    print(f\"RMSE for {target_column}:\", rmse)\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# 각각의 타겟(MLM, HLM)에 대해 학습 및 평가 수행\n",
    "best_model_MLM = train_and_evaluate('MLM')\n",
    "best_model_HLM = train_and_evaluate('HLM')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac3cd5-29c9-4b47-9d55-bf87ef74ee18",
   "metadata": {},
   "source": [
    "## 2. Mol2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98a6f2e8-164e-433f-9847-570e276612d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '{'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3m/knb96f9s4xg2t2gcrl96r6jh0000gn/T/ipykernel_11035/4031047607.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1. 모델 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_300dim.pkl'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 실제 경로로 변경 필요\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2. 데이터 전처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \"\"\"\n\u001b[1;32m   1952\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1954\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \"\"\"\n\u001b[1;32m   1460\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '{'."
     ]
    }
   ],
   "source": [
    "from mol2vec.features import mol2alt_sentence, MolSentence, DfVec, sentences2vec\n",
    "from rdkit import Chem\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 1. 모델 로드\n",
    "model = Word2Vec.load('model_300dim.pkl')  # 실제 경로로 변경 필요\n",
    "\n",
    "# 2. 데이터 전처리\n",
    "train_data = pd.read_csv('./submissions/train_linear.csv')\n",
    "train_data['sentence'] = train_data.apply(lambda x: MolSentence(mol2alt_sentence(Chem.MolFromSmiles(x['SMILES']), 1)), axis=1)\n",
    "\n",
    "# 3. 임베딩 생성\n",
    "train_data['mol2vec'] = [DfVec(x) for x in sentences2vec(train_data['sentence'], model, unseen='UNK')]\n",
    "\n",
    "# 이후에는 임베딩된 데이터를 사용하여 예측 모델을 학습하거나 다른 분석을 수행할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b6c5467-a16d-45d2-a163-f7cd79455eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mol2vec.features import mol2alt_sentence\n",
    "from rdkit import Chem\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 1. 데이터 전처리\n",
    "train_data = pd.read_csv('./submissions/train_linear.csv')\n",
    "sentences = [mol2alt_sentence(Chem.MolFromSmiles(smiles), 1) for smiles in train_data['SMILES']]\n",
    "\n",
    "# 2. Word2Vec 학습\n",
    "model = Word2Vec(sentences, vector_size=300, window=10, min_count=1, workers=4)\n",
    "model.save(\"mol2vec_model.pkl\")\n",
    "\n",
    "# 이후에는 학습된 모델을 불러와서 필요한 변환을 수행할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29843c-347d-4506-8ff1-8862fb1195bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
