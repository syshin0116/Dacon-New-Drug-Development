{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f951b269-73c9-4564-8508-a26438882e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dgl\n",
    "from rdkit import Chem\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8baa7a5-f008-4a2c-a12d-ef31a64b8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc275291-c12c-4676-a113-efc31533e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom):\n",
    "    atom_types = ['C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na', 'Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H', 'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr', 'Pt', 'Hg', 'Pb', 'Unknown']\n",
    "    return [1 if atom.GetSymbol() == atom_type else 0 for atom_type in atom_types]\n",
    "\n",
    "def mol_to_graph(mol):\n",
    "    g = dgl.DGLGraph()\n",
    "    g.add_nodes(mol.GetNumAtoms())\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        g.add_edges(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n",
    "        g.add_edges(bond.GetEndAtomIdx(), bond.GetBeginAtomIdx())\n",
    "    \n",
    "    # Assign atom features to nodes\n",
    "    g.ndata['h'] = torch.tensor([atom_features(atom) for atom in mol.GetAtoms()])\n",
    "    \n",
    "    return g\n",
    "\n",
    "\n",
    "# Convert SMILES to molecular graphs with features\n",
    "train_mols = [Chem.MolFromSmiles(smiles) for smiles in train_data['SMILES']]\n",
    "train_graphs = [mol_to_graph(mol) for mol in train_mols if mol]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d80939ea-e7ec-43c9-8a54-dcbe11765c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_data[['MLM', 'HLM']].values\n",
    "labels = torch.tensor(labels, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71d9f6c-df90-42da-a736-e2fc1b4f0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            GraphConv(in_dim, hidden_dim, activation=F.relu),\n",
    "            GraphConv(hidden_dim, hidden_dim, activation=F.relu)\n",
    "        ])\n",
    "        self.classify = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        h = features\n",
    "        # print(\"Initial feature shape:\", h.shape)\n",
    "        \n",
    "        for idx, conv in enumerate(self.layers):\n",
    "            h = conv(g, h)\n",
    "            # print(f\"Feature shape after layer {idx+1}:\", h.shape)\n",
    "        \n",
    "        g.ndata['h'] = h\n",
    "        logits = self.classify(dgl.mean_nodes(g, 'h'))\n",
    "        # print(\"Output logits shape:\", logits.shape)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "# Use the correct input size for the model based on the size of the atom features\n",
    "input_size = train_graphs[0].ndata['h'].shape[1]\n",
    "model = GNNModel(in_dim=input_size, hidden_dim=128, out_dim=2)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b75a7fc0-0d40-4c89-b126-228a4ad5299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = labels.mean(dim=0)\n",
    "std = labels.std(dim=0)\n",
    "normalized_labels = (labels - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "836fcbe2-7ba8-4bf5-abce-fea23dd3c31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at graph index 0. Graph node feature shape: torch.Size([28, 128])\n",
      "CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC\n",
      "Epoch 1, Loss: 0.0\n",
      "Error at graph index 0. Graph node feature shape: torch.Size([28, 128])\n",
      "CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC\n",
      "Epoch 2, Loss: 0.0\n",
      "Error at graph index 0. Graph node feature shape: torch.Size([28, 128])\n",
      "CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC\n",
      "Epoch 3, Loss: 0.0\n",
      "Error at graph index 0. Graph node feature shape: torch.Size([28, 128])\n",
      "CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC\n",
      "Epoch 4, Loss: 0.0\n",
      "Error at graph index 0. Graph node feature shape: torch.Size([28, 128])\n",
      "CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC\n",
      "Epoch 5, Loss: 0.0\n",
      "Error at graph index 0. Graph node feature shape: torch.Size([28, 128])\n",
      "CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC\n",
      "Epoch 6, Loss: 0.0\n",
      "Error at graph index 0. Graph node feature shape: torch.Size([28, 128])\n",
      "CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC\n",
      "Epoch 7, Loss: 0.0\n",
      "Error at graph index 0. Graph node feature shape: torch.Size([28, 128])\n",
      "CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC\n",
      "Epoch 8, Loss: 0.0\n",
      "Error at graph index 0. Graph node feature shape: torch.Size([28, 128])\n",
      "CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC\n",
      "Epoch 9, Loss: 0.0\n",
      "Error at graph index 0. Graph node feature shape: torch.Size([28, 128])\n",
      "CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC\n",
      "Epoch 10, Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(10):  # Assume 10 epochs for this example\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for idx, g in enumerate(train_graphs):\n",
    "        try:\n",
    "            logits = model(g, g.ndata['h'])\n",
    "            loss = criterion(logits, normalized_labels[idx].unsqueeze(0))  # Use normalized_labels here\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error at graph index {idx}. Graph node feature shape: {g.ndata['h'].shape}\")\n",
    "            problematic_mol = train_mols[idx]\n",
    "            print(Chem.MolToSmiles(problematic_mol))\n",
    "            break  # Let's break the loop to inspect the problematic molecule\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_graphs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d37ea7c-6c6e-43b6-8855-99452601ec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[0.0833, 0.0045]], grad_fn=<AddmmBackward0>)\n",
      "Loss: 0.08334333449602127\n"
     ]
    }
   ],
   "source": [
    "# Extract the problematic graph and its corresponding label\n",
    "problematic_graph = train_graphs[0]\n",
    "problematic_label = normalized_labels[0]  # Use normalized_label here\n",
    "\n",
    "# Forward pass with just the problematic graph\n",
    "logits = model(problematic_graph, problematic_graph.ndata['h'])\n",
    "loss = criterion(logits, problematic_label.unsqueeze(0))\n",
    "print(\"Logits:\", logits)\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f91f0e2-af58-44a5-857f-77ea58ad742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "# Featurize train data\n",
    "featurizer = dc.feat.ConvMolFeaturizer()\n",
    "train_features = featurizer.featurize(train_data['SMILES'])\n",
    "train_dataset = dc.data.NumpyDataset(X=train_features, \n",
    "                                     y=train_data[['MLM', 'HLM']].values)\n",
    "\n",
    "# Featurize test data\n",
    "test_features = featurizer.featurize(test_data['SMILES'])\n",
    "test_dataset = dc.data.NumpyDataset(X=test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03f4fde5-36e4-44ee-8899-9c2756703794",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KerasModel' from 'deepchem.models' (/Users/syshin/miniforge3/envs/pytorch/lib/python3.9/site-packages/deepchem/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepchem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphConvModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m GraphConvModel(n_tasks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.9/site-packages/deepchem/models/graph_models.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepchem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmol_graphs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvMol\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepchem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_one_hot\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepchem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasModel, layers\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepchem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m L2Loss, SoftmaxCrossEntropy, Loss\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepchem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m undo_transforms\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'KerasModel' from 'deepchem.models' (/Users/syshin/miniforge3/envs/pytorch/lib/python3.9/site-packages/deepchem/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "from deepchem.models.graph_models import GraphConvModel\n",
    "import tensorflow\n",
    "model = GraphConvModel(n_tasks=2, mode='regression', dropout=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cada3f-4679-4084-aa71-f4ee524fbde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, [metric]))\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, [metric]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10e06265-ac10-4620-a0af-a50d09a93081",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GNNModel' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(test_dataset)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GNNModel' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade554aa-a61d-4e86-bd95-7b0094160033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
